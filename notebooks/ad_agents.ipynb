{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGENTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/temesgen_gebreabzgi/Tenv/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects: [{'bbox': (50, 50, 100, 100), 'label': 'Logo'}]\n",
      "Colors: [[218.18092283 113.02698577  75.32102231]\n",
      " [ 11.39495018   6.88686595   9.30965328]\n",
      " [251.77187974 249.1893474  245.93488473]\n",
      " [  1.29373487 145.55770783 160.93916465]\n",
      " [144.23347073  25.93336356  10.61686727]]\n",
      "Positions: [(100, 100)]\n",
      "Extracted Text:  \n",
      "\n",
      "Tas i Tas\n",
      "or SWIPE Ras\n",
      "\n",
      "4 PROTEGE ed ue\n",
      "\n",
      " \n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class ImageAnalysisAgent:\n",
    "    def __init__(self, image_path):\n",
    "        self.image = cv2.imread(image_path)\n",
    "        self.rgb_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def object_identification(self):\n",
    "        # Use a pre-trained model like YOLO or Faster R-CNN for object detection\n",
    "        # For simplicity, let's assume we have a function detect_objects\n",
    "        objects = detect_objects(self.rgb_image)\n",
    "        return objects\n",
    "\n",
    "    def color_identification(self, num_colors=5):\n",
    "        pixels = self.rgb_image.reshape((-1, 3))\n",
    "        kmeans = KMeans(n_clusters=num_colors)\n",
    "        kmeans.fit(pixels)\n",
    "        colors = kmeans.cluster_centers_\n",
    "        return colors\n",
    "\n",
    "    def position_extraction(self, objects):\n",
    "        positions = []\n",
    "        for obj in objects:\n",
    "            x, y, w, h = obj['bbox']\n",
    "            center_x, center_y = x + w // 2, y + h // 2\n",
    "            positions.append((center_x, center_y))\n",
    "        return positions\n",
    "\n",
    "    def character_recognition(self):\n",
    "        text = pytesseract.image_to_string(self.rgb_image)\n",
    "        return text\n",
    "\n",
    "def detect_objects(image):\n",
    "    # Placeholder for object detection logic\n",
    "    return [{\"bbox\": (50, 50, 100, 100), \"label\": \"Logo\"}]\n",
    "\n",
    "# Example usage\n",
    "agent = ImageAnalysisAgent('/home/temesgen_gebreabzgi/semantic_image_and_text_alignment/data/Challenge_Data/Assets/2a355ca0d306921e195591e5b2374b6a/_preview.png')\n",
    "objects = agent.object_identification()\n",
    "colors = agent.color_identification()\n",
    "positions = agent.position_extraction(objects)\n",
    "text = agent.character_recognition()\n",
    "\n",
    "print(\"Objects: \", objects)\n",
    "print(\"Colors: \", colors)\n",
    "print(\"Positions: \", positions)\n",
    "print(\"Extracted Text: \", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "source_directory = '/home/temesgen_gebreabzgi/semantic_image_and_text_alignment/data/adludio storyboard examples'\n",
    "Assests_directory = '/home/temesgen_gebreabzgi/semantic_image_and_text_alignment/data/Challenge_Data/Assets/0a22f881b77f00220f2034c21a18b854' \n",
    "destination_directory = '/home/temesgen_gebreabzgi/semantic_image_and_text_alignment/images' \n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "size = (128, 128)\n",
    "pattern = os.path.join(source_directory, '*.png')\n",
    "\n",
    "\n",
    "for infile in glob.glob(pattern):\n",
    "    file, ext = os.path.splitext(infile)\n",
    "    with Image.open(infile) as im:\n",
    "        #im.thumbnail(size)\n",
    "        #im.save(file + \".thumbnail.png\", \"PNG\")\n",
    "        im.show()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class StoryBoard:\n",
    "    @staticmethod\n",
    "    def combine_images_horizontally(images: list[Image.Image]) -> Image.Image:\n",
    "        total_width = sum(image.width for image in images)\n",
    "        max_height = max(image.height for image in images)\n",
    "        combined_image = Image.new('RGBA', (total_width, max_height))\n",
    "\n",
    "        current_x = 0\n",
    "        for image in images:\n",
    "            combined_image.paste(image, (current_x, 0))\n",
    "            current_x += image.width\n",
    "\n",
    "        return combined_image\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_images_vertically(images: list[Image.Image]) -> Image.Image:\n",
    "        total_height = sum(image.height for image in images)\n",
    "        max_width = max(image.width for image in images)\n",
    "        combined_image = Image.new('RGBA', (max_width, total_height))\n",
    "\n",
    "        current_y = 0\n",
    "        for image in images:\n",
    "            combined_image.paste(image, (0, current_y))\n",
    "            current_y += image.height\n",
    "\n",
    "        return combined_image\n",
    "\n",
    "    @staticmethod\n",
    "    def create_storyboard(images: list[list[Image.Image]]) -> Image.Image:\n",
    "        combined_rows = [StoryBoard.combine_images_horizontally(row) for row in images]\n",
    "        storyboard = StoryBoard.combine_images_vertically(combined_rows)\n",
    "        return storyboard\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define paths to images in the ./samples/ directory\n",
    "    image1_path = \"./samples/kfc-fs-320x480-sensoryvideo-storyboard.png\"\n",
    "    image2_path = \"./samples/ITC-FS-320x480-SensorySwipe-Storyboard-Rev.png\"\n",
    "    image3_path = \"./samples/Adludio-CocaCola-[BR]-[LIVE]-ifood-christmas2033-TapAndHold-FS-V3-sb.png\"\n",
    "    image4_path = \"./samples/Adludio-Volvo-[UK]-[RFP]-Volvo_Vehicle_Electrification_XC40-Tap-FS-Version_2_AJ.png\"\n",
    "    image5_path = \"./samples/Adludio-Microsoft-[FR]-[LIVE]-Windows_11_version_2-Swipe-MPU-v2.png\"\n",
    "    image6_path = \"./samples/Disney-DrStrange-FS-600x900-UserSlider-Storyboard.png\"\n",
    "\n",
    "    image1 = Image.open(image1_path)\n",
    "    image2 = Image.open(image2_path)\n",
    "    image3 = Image.open(image3_path)\n",
    "    image4 = Image.open(image4_path)\n",
    "    image5 = Image.open(image5_path)\n",
    "    image6 = Image.open(image6_path)\n",
    "\n",
    "\n",
    "    images = [\n",
    "        [image1, image2, image3],  # First row\n",
    "        [image4, image5, image6]   # Second row\n",
    "    ]\n",
    "    storyboard = StoryBoard.create_storyboard(images)\n",
    "    storyboard.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
