{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'project', 'utils']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import autogen\n",
    "print(dir(autogen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from autogen.agentchat.user_proxy_agent import UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from autogen import AssistantAgent\n",
    "#from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an asynchronous function that simulates some asynchronous task (e.g., I/O operation)\n",
    "\n",
    "\n",
    "async def my_asynchronous_function():\n",
    "    print(\"Start asynchronous function\")\n",
    "    await asyncio.sleep(2)  # Simulate some asynchronous task (e.g., I/O operation)\n",
    "    print(\"End asynchronous function\")\n",
    "    return \"input\"\n",
    "\n",
    "\n",
    "# Define a custom class `CustomisedUserProxyAgent` that extends `UserProxyAgent`\n",
    "\n",
    "\n",
    "class CustomisedUserProxyAgent(UserProxyAgent):\n",
    "    # Asynchronous function to get human input\n",
    "    async def a_get_human_input(self, prompt: str) -> str:\n",
    "        # Call the asynchronous function to get user input asynchronously\n",
    "        user_input = await my_asynchronous_function()\n",
    "\n",
    "        return user_input\n",
    "\n",
    "    # Asynchronous function to receive a message\n",
    "\n",
    "    async def a_receive(\n",
    "        self,\n",
    "        message: Union[Dict, str],\n",
    "        sender,\n",
    "        request_reply: Optional[bool] = None,\n",
    "        silent: Optional[bool] = False,\n",
    "    ):\n",
    "        # Call the superclass method to handle message reception asynchronously\n",
    "        await super().a_receive(message, sender, request_reply, silent)\n",
    "\n",
    "\n",
    "class CustomisedAssistantAgent(AssistantAgent):\n",
    "    # Asynchronous function to get human input\n",
    "    async def a_get_human_input(self, prompt: str) -> str:\n",
    "        # Call the asynchronous function to get user input asynchronously\n",
    "        user_input = await my_asynchronous_function()\n",
    "\n",
    "        return user_input\n",
    "\n",
    "    # Asynchronous function to receive a message\n",
    "    async def a_receive(\n",
    "        self,\n",
    "        message: Union[Dict, str],\n",
    "        sender,\n",
    "        request_reply: Optional[bool] = None,\n",
    "        silent: Optional[bool] = False,\n",
    "    ):\n",
    "        # Call the superclass method to handle message reception asynchronously\n",
    "        await super().a_receive(message, sender, request_reply, silent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_llm_config(model, temperature, seed):\n",
    "    config_list = [\n",
    "        {\n",
    "            \"model\": \"<model_name>\",\n",
    "            \"api_key\": \"<api_key>\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    llm_config = {\n",
    "        \"seed\": int(seed),\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": float(temperature),\n",
    "    }\n",
    "\n",
    "    return llm_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
